{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datyaset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "preprocessed_dataset_path = r\"C:\\Users\\Debajyoti\\OneDrive\\Desktop\\Generative_AI_(fine_tuned_model__detoxify_summarization\\data\\preprocess_datasets\"\n",
    "dataset = load_from_disk(preprocessed_dataset_path)\n",
    "print(\"Datyaset loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentiment_model import EvaluateToxicity,toxicity_model,toxicity_tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "from create_ppo_and_ref_model import ref_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:10, 13.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxicity [mean, std] before detox: [0.02238751995464554, 0.05002900902694688]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"google/flan-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, device_map=\"auto\")\n",
    "\n",
    "evaluate_toxicity = EvaluateToxicity(\n",
    "    toxicity_classifier_model=toxicity_model,\n",
    "    main_model=ref_model,\n",
    "    toxicity_tokenizer=toxicity_tokenizer,\n",
    "    main_tokenizer=tokenizer,\n",
    "    dataset=dataset[\"train\"],\n",
    "    num_samples=10\n",
    ")\n",
    "\n",
    "mean_before_detoxification, std_before_detoxification = evaluate_toxicity.evaluate_mean_and_variance()\n",
    "\n",
    "print(f'Toxicity [mean, std] before detox: [{mean_before_detoxification}, {std_before_detoxification}]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collator input: [{'key1': 'value1', 'key2': 'value2', 'key3': 'value3'}]\n",
      "Collator output: {'key1': ['value1'], 'key2': ['value2'], 'key3': ['value3']}\n"
     ]
    }
   ],
   "source": [
    "def collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])\n",
    "\n",
    "test_data = [{\"key1\": \"value1\", \"key2\": \"value2\", \"key3\": \"value3\"}]\n",
    "print(f'Collator input: {test_data}')\n",
    "print(f'Collator output: {collator(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Debajyoti\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:193: FutureWarning: `PPOTrainer` is deprecated and will be removed in trl v0.12. Please use `PPOv2Trainer` instead.\n",
      "  warnings.warn(\n",
      "0it [00:00, ?it/s]Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "1it [00:23, 23.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 0.007212568074464798\n",
      "ppo/returns/mean: 0.06715904176235199\n",
      "ppo/policy/advantages_mean: 0.005440084263682365\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:46, 23.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -0.005001811310648918\n",
      "ppo/returns/mean: 0.08179621398448944\n",
      "ppo/policy/advantages_mean: -0.10700567066669464\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [01:03, 20.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 0.10874038934707642\n",
      "ppo/returns/mean: 0.05560018867254257\n",
      "ppo/policy/advantages_mean: -0.006436333060264587\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [01:21, 19.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 0.06517210602760315\n",
      "ppo/returns/mean: 0.06177547946572304\n",
      "ppo/policy/advantages_mean: -0.030366972088813782\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [01:39, 18.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 0.07727505266666412\n",
      "ppo/returns/mean: 0.05446866899728775\n",
      "ppo/policy/advantages_mean: -0.04297010973095894\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [01:58, 19.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 0.021698934957385063\n",
      "ppo/returns/mean: 0.05891218036413193\n",
      "ppo/policy/advantages_mean: -0.028973421081900597\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [02:14, 17.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -0.014860151335597038\n",
      "ppo/returns/mean: 0.060565344989299774\n",
      "ppo/policy/advantages_mean: -0.13977012038230896\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [02:32, 17.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -0.05809370428323746\n",
      "ppo/returns/mean: 0.061154626309871674\n",
      "ppo/policy/advantages_mean: -0.03513656556606293\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [02:54, 19.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -0.005539754405617714\n",
      "ppo/returns/mean: 0.05540284886956215\n",
      "ppo/policy/advantages_mean: -0.04244184494018555\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [03:11, 19.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 0.0557577908039093\n",
      "ppo/returns/mean: 0.043449848890304565\n",
      "ppo/policy/advantages_mean: 0.0010683070868253708\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Successfully Training copmpleted!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from trainer import ppo_trainer, fine_tuning_instruct_model\n",
    "\n",
    "output_min_length = 100\n",
    "output_max_length = 400\n",
    "max_ppo_epoch = 10\n",
    "\n",
    "ppo_trainer,ppo_model = fine_tuning_instruct_model(\n",
    "    output_min_length=output_min_length,\n",
    "    output_max_length = output_max_length,\n",
    "    ppo_trainer = ppo_trainer,\n",
    "    evaluate_toxicity=evaluate_toxicity,\n",
    "    max_ppo_epoch=max_ppo_epoch\n",
    ")\n",
    "print(\"Successfully Training copmpleted!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "def save_ppo_model_and_trainer_with_pickle(ppo_model, path=\"ppo_model_trainer.pkl\"):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "    try:\n",
    "\n",
    "        save_dict = {\n",
    "            'ppo_trained_model': ppo_model.state_dict()                  \n",
    "        }\n",
    "\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(save_dict, f)\n",
    "\n",
    "        print(f\"PPO Model and PPO Trainer saved successfully at {path}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error while saving PPO model and trainer: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO Model and PPO Trainer saved successfully at C:\\Users\\Debajyoti\\OneDrive\\Desktop\\Generative_AI_(fine_tuned_model__detoxify_summarization\\models\\ppo_trained_models.pkl\n"
     ]
    }
   ],
   "source": [
    "path = r\"C:\\Users\\Debajyoti\\OneDrive\\Desktop\\Generative_AI_(fine_tuned_model__detoxify_summarization\\models\\ppo_trained_models.pkl\"\n",
    "save_ppo_model_and_trainer_with_pickle(ppo_model,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to the correct device\n",
    "ppo_model = ppo_model.to(device)\n",
    "toxicity_model = toxicity_model.to(device)\n",
    "\n",
    "# Move dataset to the correct device\n",
    "def move_to_device(batch, device):\n",
    "    if isinstance(batch, dict):\n",
    "        return {k: move_to_device(v, device) for k, v in batch.items()}\n",
    "    elif isinstance(batch, list):\n",
    "        return [move_to_device(v, device) for v in batch]\n",
    "    return batch.to(device)\n",
    "\n",
    "dataset[\"train\"] = dataset[\"train\"].map(lambda batch: move_to_device(batch, device), batched=True)\n",
    "\n",
    "# Ensure the tokenizer uses the correct device for input tensors\n",
    "evaluate_toxicity_after_training = EvaluateToxicity(\n",
    "    toxicity_classifier_model=toxicity_model,\n",
    "    main_model=ppo_model,\n",
    "    toxicity_tokenizer=toxicity_tokenizer,\n",
    "    main_tokenizer=tokenizer,\n",
    "    dataset=dataset[\"train\"],\n",
    "    num_samples=10\n",
    ")\n",
    "\n",
    "mean_after_detoxification, std_after_detoxification = evaluate_toxicity_after_training.evaluate_mean_and_variance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_improvement = (mean_before_detoxification - mean_after_detoxification) / mean_before_detoxification\n",
    "std_improvement = (std_before_detoxification - std_after_detoxification) / std_before_detoxification\n",
    "\n",
    "print(f'Percentage improvement of toxicity score after detoxification:')\n",
    "print(f'mean: {mean_improvement*100:.2f}%')\n",
    "print(f'std: {std_improvement*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from trl.core import LengthSampler\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# LengthSampler setup\n",
    "output_min_length = 100\n",
    "output_max_length = 400\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"min_length\": 5,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True\n",
    "}\n",
    "\n",
    "def predict_test_data(ref_model, ppo_model, dataset,tokenizer):\n",
    "    batch_size = 20\n",
    "    compare_results = {}\n",
    "\n",
    "    # Select the batch of data\n",
    "    df_batch = dataset[\"test\"][0:batch_size]\n",
    "\n",
    "    compare_results[\"query\"] = df_batch[\"query\"]\n",
    "    prompt_tensors = df_batch[\"input_ids\"]\n",
    "\n",
    "    # Move models to the correct device\n",
    "    ref_model = ref_model.to(device)\n",
    "    ppo_model = ppo_model.to(device)\n",
    "\n",
    "    summary_tensors_ref = []\n",
    "    summary_tensors_ppo = []\n",
    "\n",
    "    # Process each sample in the batch\n",
    "    for i in tqdm(range(batch_size)):\n",
    "        gen_len = output_length_sampler()\n",
    "        generation_kwargs[\"max_new_tokens\"] = gen_len\n",
    "\n",
    "        # Move the input tensor to the correct device\n",
    "        prompt_tensor = torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device)\n",
    "\n",
    "        # Generate summary from the reference model\n",
    "        summary_ref = ref_model.generate(\n",
    "            input_ids=prompt_tensor,\n",
    "            **generation_kwargs\n",
    "        ).squeeze()[-gen_len:]\n",
    "        summary_tensors_ref.append(summary_ref)\n",
    "\n",
    "        # Generate summary from the PPO model\n",
    "        summary_ppo = ppo_model.generate(\n",
    "            input_ids=prompt_tensor,\n",
    "            **generation_kwargs\n",
    "        ).squeeze()[-gen_len:]\n",
    "        summary_tensors_ppo.append(summary_ppo)\n",
    "\n",
    "    compare_results[\"response_before\"] = [tokenizer.decode(summary_tensors_ref[i]) for i in range(batch_size)]\n",
    "    compare_results[\"response_after\"] = [tokenizer.decode(summary_tensors_ppo[i]) for i in range(batch_size)]\n",
    "    return compare_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:27<00:00,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution successfully completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "compare_results = predict_test_data(ref_model=ref_model,\n",
    "                                    ppo_model = ppo_model,\n",
    "                                    dataset = dataset,\n",
    "                                    tokenizer = tokenizer)\n",
    "\n",
    "print(\"Execution successfully completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': [\"Summarize the following conversation: #Person1#: Good afternoon doctor. #Person2#: Good afternoon, Mrs. Brown. Wow, what's wrong with this little boy? #Person1#: He is my son Jim. He's gotta cough. #Person2#: How long has he been like this? #Person1#: Ever since last night. #Person2#: Has he had anything to eat today? #Person1#: Yes, he had a little milk and an egg this morning. #Person2#: Well, Mrs. Brown. I think he's caught a cold. #Person1#: Is it serious? #Person2#: No, it's nothing serious, but he better stay at home and rest. #Person1#: Thank you very much. #Person2#: You're welcome. Summary:\", \"Summarize the following conversation: #Person1#: Let me tell you what happened to my homework. #Person2#: OK, go ahead--what is the excuse THIS time? #Person1#: Actually, I did it, but then it got lost. #Person2#: Could you have gotten it done at another time? #Person1#: Yes, I could. #Person2#: You have never missed an assignment before--when will you be making this one up? #Person1#: I'll make it up early next week. #Person2#: That would work, but don't let it happen again. #Person1#: I'll try. #Person2#: That will solve it then. Let's work hard to not let it happen again. Summary:\", \"Summarize the following conversation: #Person1#: Anything else? #Person2#: Yes, one last thing. How much holiday time do you give your employees every year? #Person1#: Our employees receive fifteen days of paid vacation every year. If you don't use the full fifteen days, they carry over to the following year. #Person2#: How about sick days? #Person1#: You get five paid sick days. #Person2#: Any other benefits? #Person1#: Yes, we have an excellent retirement plan and medical insurance as well. #Person2#: Great. Thanks so much for your time. #Person1#: We'll contact you soon, Ted. Thanks for coming in. Summary:\", \"Summarize the following conversation: #Person1#: I heard there is a big yard sale at weeks this saturday morning, i will go there to see if there is some nice clothes, do you want to go with me? #Person2#: Well, i want to go to the university flea market, they got times of books, DVDs, and a lot of nice clothing, too. #Person1#: How about we go to the yard sale first and then to the university flea market? #Person2#: Good idea, let's shop to we drop! Summary:\", \"Summarize the following conversation: #Person1#: Now tell me, what's your problem? #Person2#: I don't feel like eating. And I cannot sleep well. #Person1#: Do you have a fever? #Person2#: Yes, a low fever. I feel terrible. Am I dying? #Person1#: Certainly not. Take one of these white pills three times a day. #Person2#: Before the meals or after the meals? #Person1#: After the meals. And do not forget to take two sleeping pills before going to bed. Summary:\", \"Summarize the following conversation: #Person1#: Thank God! I am finished writing that service guide! It took me forever! #Person2#: When did you finish? #Person1#: This morning! No more overtime, and no more headaches! #Person2#: Well, I ' m glad to hear it. Have a cup of coffee! Summary:\", 'Summarize the following conversation: #Person1#: This apartment is great, but could I upgrade a few things? #Person2#: What are you unhappy with? #Person1#: I want to have a different color carpet. #Person2#: If you agree to pay more money, you could upgrade the carpet. #Person1#: Would it cost a lot more? #Person2#: It could be as little as 2 dollars or as much as 10 dollars more per square yard. #Person1#: I was also wondering if it would be possible to pick a different paint color. #Person2#: Bring me a paint sample to look at, and I will consider it. #Person1#: When can you finish with the new carpet and paint? #Person2#: Your new apartment can be recarpeted and repainted by next Tuesday. Summary:', \"Summarize the following conversation: #Person1#: Good morning! Can I help you? #Person2#: Yes, let me see some of your hats, please. #Person1#: OK, come this way, please. How does this one fit you? #Person2#: It's a little bit tight. #Person1#: Let me stretch it for you. How is that now? #Person2#: Yes, it fits all right now. I'll take it. Please put it in a bag and I'll take along. #Person1#: OK. Here you are. #Person2#: How much is it? #Person1#: Thirty-five yuan. #Person2#: Here is the money. #Person1#: Thanks. Nothing else, today? #Person2#: Nothing else, thank you. Summary:\", \"Summarize the following conversation: #Person1#: Here comes the Sunday newspaper again. #Person2#: Can I have the sports section? #Person1#: Sure, here you are. #Person2#: Let me check if there's anything exciting next week? #Person1#: You mean football matches, do you? #Person2#: Yes. Here it is! There will be a great football match on Monday at the City stadium. #Person1#: So you'll go and watch it. #Person2#: Of course. But do you think they will cancel the football match if it rains on Monday? #Person1#: I think they will. #Person2#: If they do cancel it, will they have it on Wednesday? #Person1#: I really can't tell. #Person2#: I want to make sure about it because I will be out of town on Wednesday. I really can't miss the game. #Person1#: Why don't you check the weather on the internet? #Person2#: Good idea. I'll do it right now. Summary:\", \"Summarize the following conversation: #Person1#: I wish I knew who had moved our flower pots. #Person2#: It was me. I am so sorry. #Person1#: What did you think you were doing? #Person2#: I had to move it, so that I can get my bike through. #Person1#: How dare you be so inconsiderate? That's wrong. #Person2#: I am awfully sorry. I didn't think you would mind so much. #Person1#: Never do that again. #Person2#: I promise. Summary:\", 'Summarize the following conversation: #Person1#: How many persons are there in your family? #Person2#: There are three, my parents and I. #Person1#: Do you live together? #Person2#: No, I live alone in a flat near my work place. #Person1#: Do you often go back to see your parents. #Person2#: Yes, almost once a week. Summary:', \"Summarize the following conversation: #Person1#: Hey Mark. What are you doing? #Person2#: Just watching some TV. #Person1#: Anything interesting on? #Person2#: Not really. Just watching the sports highlight on ESPN. #Person1#: So I take it you're pretty bored too. #Person2#: Just killing time until I find something to do. What are you going to do? #Person1#: It's Saturday and we are sitting at home doing nothing. What's wrong with us? #Person2#: You wanna shoot some hoops? #Person1#: I already tried to call up some of the guys, but they are all busy. #Person2#: Where's your girlfriend? I thought you were going out with her today. #Person1#: She's out shopping with her friends. #Person2#: Let's go to Starbucks and think of something to do then. #Person1#: Aright. Do you have any cigarettes? #Person2#: I only have a couple left. Why don't you pick some up on the way. #Person1#: Ok. See you there in about 30 minutes. #Person2#: Aright. See you there. Summary:\", \"Summarize the following conversation: #Person1#: Hello, is this apartment management? #Person2#: Can I help you? #Person1#: Yes, this is the tenant of apartment ten. I guess my kitchen sink is clogging up again, and so is the bathtub. #Person2#: Alright. I'll send someone over tomorrow. #Person1#: Um, I'd really appreciate it if you send someone over to fix it today. It's really a bother. I can't cook or take a shower. #Person2#: Fine, I'll be up in a few minutes. #Person1#: Thanks, I appreciated it. Summary:\", \"Summarize the following conversation: #Person1#: I just bought a new dress. What do you think of it? #Person2#: You look really great in it. So are you going to a job interview or a party? #Person1#: No, I was invited to give a talk in my school. #Person2#: So how much did you pay for it? #Person1#: I pay just $70 for it. I saved $30. #Person2#: That's really a bargain. #Person1#: You're right. Well, what did you do while I was out shopping? #Person2#: I watched TV for a while and then I did some reading. It wasn't a very interesting book so I just read a few pages. Then I took a shower. #Person1#: I thought you said you were going to see Mike. #Person2#: I'll go and visit him at his home tomorrow. He'll return home tomorrow morning. #Person1#: I'm glad he can finally returned home after that accident. Summary:\", \"Summarize the following conversation: #Person1#: What's your favorite movie? #Person2#: My favorite movie is Superbad. #Person1#: Oh, why is that? #Person2#: It's the funniest movie that I've ever seen. #Person1#: That's true. It is a very funny movie. #Person2#: You've seen it before? #Person1#: Yes, I saw that movie the first day it came out in theaters. #Person2#: Didn't you laugh through the whole movie? I did. #Person1#: Me too. That movie brought tears to my eyes. #Person2#: Mine too. #Person1#: I have it on DVD at my house if you want to come over and watch it. #Person2#: Sure, let's go. Summary:\", \"Summarize the following conversation: #Person1#: I always think everybody looks down on me #Person2#: Don't be that negative. #Person1#: How can you be optimistic? You can see it in their eyes. #Person2#: I find it there is no meaning in living this world. #Person1#: Don't be that negative. #Person2#: Really, life is so boring. Summary:\", \"Summarize the following conversation: #Person1#: Jane, have you got time this evening? #Person2#: Not really, I'm afraid. But I'll be free tomorrow. #Person1#: Well, I'll be busy then. Maybe another time, I'll ring up to see if you are not engaged in anything later. #Person2#: Sure. See you. Summary:\", \"Summarize the following conversation: #Person1#: Susan, do you think we could study together sometime this weekend? #Person2#: I don't see why not. Are you doing anything on tomorrow night? #Person1#: I can't on tomorrow. I'm going out with some friends. #Person2#: Well, how about the following night? #Person1#: No, I can't on Saturday either. My sister and her husband are coming to town and I want to show them around. #Person2#: Sunday, then? #Person1#: Well, I'll probably sleep all morning and in the afternoon I want to go to the football game. #Person2#: Michael, that leaves Monday, the night before the test. #Person1#: Actually, I've got plans for Monday night too. How about early Tuesday morning? #Person2#: Michael, the test is on Tuesday morning. Summary:\", \"Summarize the following conversation: #Person1#: They're here! Now that's speedy service! And they arrived within two days of each other! #Person2#: What are you waiting for? Rip ' em open! #Person1#: Wow... this shirt is nice, but looks big. #Person2#: It's nice, but how much did you end up paying? #Person1#: With the shipping included--seventy dollars. #Person2#: Hmm... not so hot. They sell them here for about that. Summary:\", \"Summarize the following conversation: #Person1#: How's your father been? #Person2#: He's been out of work for a couple of days. #Person1#: What's wrong with him? #Person2#: He has a bad cold. #Person1#: Well, tell him to take it easy and that I hope he feels better. #Person2#: Thanks. I'll tell him. Summary:\"], 'response_before': [\"<pad> Jim's cough is always suspected.</s>\", \"<pad> #Person1: I skipped my homework. #Person2: Well, it turned out to be lost. Sorry, I didn't get it done, did, but it wasn't done at a certain time. I might come up with a solution to theproblem next week.</s>\", '<pad> Employees receive allowance of $50 a week. Employees should also be reimbursed 1 extra day of vacation per year.</s>', '<pad> The yard sale on Saturday morning is at 7 am.</s>', '<pad> When does trouble start; how does it get better?</s>', '<pad> The service guide will be finished now.</s>', '<pad> Your carpet and paint may be installed by a professional. If your carpet is indoors, the house must be thoroughly cleaned annually.</s>', '<pad> Your company is doing all the ironing. Should you need anything else, let me know.</s>', '<pad> Every Friday and Saturday in the other newspaper is a football match.</s>', '<pad> The person was able to leave the flower pots for the child but the gardener decided to move them altogether. They apologized and shared their feelings.</s>', '<pad> Natural Business Discover Online and Where to Locate a Supplier. Find key contact information and contact information on Marie Lewis Redwood (Mary Hopkins), sometimes known as Marie Lewis Redwood. Place the Request by . To the Feedback section of Social Media, click on the profile picture you wish to include and click on the Driver Information Opt in.</s>', \"<pad> So many people go to Starbucks for a smoke's-free day today.</s>\", '<pad> @FanxProPERR-CHURCH@BBCG/The_Apartment_Next_the_library@BBCG ################### A presiding tenant requests that a customer contact him/her.</s>', '<pad> On Friday at school, Person1 gave a talk.</s>', '<pad> Nearly three weeks ago, Old Man McCormick contacted Person 2 to come and see his favorite movie, Superbad.</s>', \"<pad> #Person1: I never think everyone looks down on me. #Person2: I don't believe that everything is the same however others do.</s>\", \"<pad> #Person1#: Jane, do you have an event on tomorrow after work? #Person2#: Um, I think I'll be torn this evening and tomorrow.</s>\", \"<pad> No, we can't for the night this evening, either. Have you two planned together?</s>\", \"<pad> Messaged to the customer by the manager Brian Adams to give them their agreed shipping and arrival start times. Brian's part in their buying process with the store's staff. Brian got a great shirt and arrived within two days. He is excited to see that they can now both help him find what he was looking for. One customer went through their time comparing potential customers and demand a certain moment of time. The outstanding response of Captain Roberts on leadership develops the strength of the line.</s>\", \"<pad> It is their father's bad cold.</s>\"], 'response_after': ['<pad> The little boy is doing OK today.</s>', '<pad> Problem solved. Learn who or do it to make up.</s>', '<pad> She spoke about their benefits.</s>', '<pad> Whole8% every time we see what brands we liked and dislike, a liird dressing board beatsThemis!</s>', '<pad> Practice taking these drugs, which work like a friendly, friendly drug.</s>', '<pad> Paul studied to complete the service guide and learned about life at the recession.</s>', \"<pad> #Posk #1: The paint color is the best. #Person1#: If it's so, you can even dye it any color.</s>\", '<pad> Lei Xing.</s>', '<pad> The football match will be fixed on Monday, so everyone will be there to watch it.</s>', '<pad> What was beebie to them?</s>', '<pad> #Person1#: same family who live alone do not have children</s>', '<pad> Sitting at Home watching ESPN, and Prime cut in gym.</s>', \"<pad> On January 6, ground 7, a tenant notice stated that #QoE Apartment Tenkill at Fort Madison and the associated room for rent was no longer available for lease. #Person1#: <unk> We wouldn't visit your apartment unless you owned the required premises; if you owned the other one there were already monthly accounts in the same tenant group because rent VA was shared and was living in the cooperative. #Person2#: Thats right. If you let people stay in the suite, they get more of it. #Person3knollfldrp</s>\", \"<pad> Say so you bought a new dress you'd bought if you wish.</s>\", '<pad> The post someone calls carries all day.</s>', '<pad> Person 1: You see it indoors and any day I never ask a person I like being negative</s>', '<pad> #Person1Zegerred it over with #Person2SoloundHe Yes!</s>', '<pad> Employee1: Please study this weekend by submitting paper M-5 to the school newspaper.</s>', '<pad> If you are looking at mobile equipment in a classroom then what did you get? Learn how to, buy, wash or explain anything about Mobile Computers and create or store Virtual Computers, make videos, according to the dictionary in the library from any app or online according to your walking gait towards your faster, live http:// Knowledgebase. This article feeds back.</s>', '<pad> A friend of the donor recommended that a person should take precautions to avoid his patient telling them he lost balance in payments which might include a disputed sliding scale.</s>']}\n"
     ]
    }
   ],
   "source": [
    "print(compare_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query\n",
      "response_before\n",
      "response_after\n"
     ]
    }
   ],
   "source": [
    "for key in compare_results.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file sent to destined path: C:\\Users\\Debajyoti\\OneDrive\\Desktop\\Generative_AI_(fine_tuned_model__detoxify_summarization\\results_csv_file\\final_comparison_result.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_result_path = r\"C:\\Users\\Debajyoti\\OneDrive\\Desktop\\Generative_AI_(fine_tuned_model__detoxify_summarization\\results_csv_file\\final_comparison_result.csv\"\n",
    "\n",
    "# Save the comparison results to CSV\n",
    "result_df = pd.DataFrame(compare_results)\n",
    "result_df.to_csv(test_result_path, index=False)\n",
    "\n",
    "# Print success message\n",
    "print(f\"CSV file sent to destined path: {test_result_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response_before</th>\n",
       "      <th>response_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summarize the following conversation: #Person1...</td>\n",
       "      <td>&lt;pad&gt; Jim's cough is always suspected.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; The little boy is doing OK today.&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Summarize the following conversation: #Person1...</td>\n",
       "      <td>&lt;pad&gt; #Person1: I skipped my homework. #Person...</td>\n",
       "      <td>&lt;pad&gt; Problem solved. Learn who or do it to ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summarize the following conversation: #Person1...</td>\n",
       "      <td>&lt;pad&gt; Employees receive allowance of $50 a wee...</td>\n",
       "      <td>&lt;pad&gt; She spoke about their benefits.&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Summarize the following conversation: #Person1...</td>\n",
       "      <td>&lt;pad&gt; The yard sale on Saturday morning is at ...</td>\n",
       "      <td>&lt;pad&gt; Whole8% every time we see what brands we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Summarize the following conversation: #Person1...</td>\n",
       "      <td>&lt;pad&gt; When does trouble start; how does it get...</td>\n",
       "      <td>&lt;pad&gt; Practice taking these drugs, which work ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Summarize the following conversation: #Person1...   \n",
       "1  Summarize the following conversation: #Person1...   \n",
       "2  Summarize the following conversation: #Person1...   \n",
       "3  Summarize the following conversation: #Person1...   \n",
       "4  Summarize the following conversation: #Person1...   \n",
       "\n",
       "                                     response_before  \\\n",
       "0         <pad> Jim's cough is always suspected.</s>   \n",
       "1  <pad> #Person1: I skipped my homework. #Person...   \n",
       "2  <pad> Employees receive allowance of $50 a wee...   \n",
       "3  <pad> The yard sale on Saturday morning is at ...   \n",
       "4  <pad> When does trouble start; how does it get...   \n",
       "\n",
       "                                      response_after  \n",
       "0        <pad> The little boy is doing OK today.</s>  \n",
       "1  <pad> Problem solved. Learn who or do it to ma...  \n",
       "2          <pad> She spoke about their benefits.</s>  \n",
       "3  <pad> Whole8% every time we see what brands we...  \n",
       "4  <pad> Practice taking these drugs, which work ...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
